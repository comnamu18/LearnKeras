{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=train_images.reshape((60000,28*28))\n",
    "train_images=train_images.astype('float32')/255\n",
    "\n",
    "test_images=test_images.reshape((10000,28*28))\n",
    "test_images=test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gogi\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.2597 - accuracy: 0.9256 0s - loss: 0.2709 - \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1036 - accuracy: 0.9698\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0690 - accuracy: 0.9790\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0503 - accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0380 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1525e8f5408>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,train_labels,epochs=5,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 41us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06716737910429947 0.9789000153541565\n"
     ]
    }
   ],
   "source": [
    "print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x152018db4c8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test = plt.imread('C:/Users/gogi/Desktop/8.jpg')\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reshape(3,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (28, 28, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-a3f44ff12292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have 2 dimensions, but got array with shape (28, 28, 3)"
     ]
    }
   ],
   "source": [
    "network.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
